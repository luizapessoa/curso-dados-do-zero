# curso-dados-do-zero  
Reposit√≥rio criado para armazenar materiais e projetos desenvolvidos durante o curso **"Dados do Zero: Excel, SQL, Python e AWS com Projetos Reais"**, com foco no aprendizado pr√°tico em **an√°lise e engenharia de dados**.

---

## 1. Excel  

Plataforma utilizada: **Google Sheets**  

Nesta etapa do curso, foi realizada a **an√°lise inicial dos dados** utilizando planilhas, f√≥rmulas e dashboards para explorar e visualizar as informa√ß√µes de forma pr√°tica.  

### An√°lise inicial dos dados  

- Importa√ß√£o da base de dados em formato `.csv`.  
- Utiliza√ß√£o de **tabelas din√¢micas** para resumo das informa√ß√µes por categoria e produto.  
- Aplica√ß√£o de **filtros autom√°ticos** para segmentar dados de vendas e regi√µes.  

### F√≥rmulas e fun√ß√µes aplicadas  
- **SOMA** e **M√âDIA** para c√°lculos b√°sicos de total de vendas e m√©dias por categoria.  
- **PROCV / XLOOKUP** para cruzar informa√ß√µes entre planilhas (ex.: cliente e produto).  
- **SE** e **SEERRO** para classifica√ß√µes condicionais e tratamento de dados ausentes.  
- **CONT.SE / CONT.SES** para contagem filtrada de produtos e clientes.  

### Visualiza√ß√£o de dados  
- Cria√ß√£o de **gr√°ficos de colunas, pizza e linha** para an√°lise visual do desempenho de vendas.  
- Formata√ß√£o condicional para destacar valores acima ou abaixo da m√©dia.  
- Dashboard simples com indicadores de total de vendas, ticket m√©dio e produtos mais vendidos.  

---

**[Veja a planilha utilizada aqui](./dados-venda-empresav2%20(1).xlsx)**  
 

---
## SQL

Plataforma utilizada: **SQLite**  

Nesta etapa, foram aplicados **conceitos de banco de dados e linguagem SQL** para manipula√ß√£o e an√°lise de dados, utilizando consultas com filtros, jun√ß√µes e agrega√ß√µes.  

- **Filtros** e **queries** utilizados na an√°lise inicial dos dados.

---

### Fun√ß√µes de agrega√ß√£o:

Resumem informa√ß√µes da tabela, como contar categorias distintas e identificar o maior valor de estoque
```
SELECT count(DISTINCT categoria) as total_categorias from produtos;
```

```
SELECT nome_produto, MAX(quantidade_estoque) AS estoque_total from produtos;
```

### Join entre tabelas:

Consulta que realiza jun√ß√£o entre as tabelas vendas, produtos e clientes para combinar informa√ß√µes completas sobre as vendas, produtos e perfis de clientes.
```
SELECT v.data_venda, v.nome_cliente, v.estado,
p.nome_produto, p.categoria, v.quantidade, 
p.preco_unitario, v.total_venda, c.celular, c.email, c.idade
FROM vendas v join produtos p 
on v.produto = p.nome_produto
JOIN clientes c 
ON v.id_cliente = c.id_cliente
WHERE C.idade > 40
order by v.data_venda desc;
```

### Left join:

Consulta que retorna todos os clientes, incluindo aqueles que ainda n√£o realizaram vendas, preservando os registros da tabela principal (clientes).
````
SELECT c.nome_cliente, v.data_venda, v.produto, v.total_venda
From clientes c
LEFT JOIN vendas v
ON c.nome_cliente = v.nome_cliente
ORDER by c.nome_cliente;
````

### Case when:

Consulta que utiliza a estrutura condicional `CASE WHEN` para classificar clientes conforme o valor total da venda, definindo-os como ‚ÄúVIP‚Äù ou ‚ÄúCOMUM‚Äù.
```
SELECT * , 
  CASE 
    WHEN total_venda > 10000 THEN 'VIP'
      ELSE 'COMUM'
    END AS status_cliente
FROM vendas;
```

---

**[Veja o script completo aqui](./analise.sql)**


## 3. Python

Plataforma utilizada: Google Colab

Nesta etapa foram aplicadas **bibliotecas de an√°lise de dados** como **Pandas, NumPy, Matplotlib e Seaborn** para manipula√ß√£o, visualiza√ß√£o e extra√ß√£o de insights.

## importar bibliotecas

``` firstanalysis.py
import pandas as pd 
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
```

### - importar dataframe

```
from google.colab import files
uploaded = files.upload()
```
ps: depois de rodar, adiciona o arquivo csv em 'Escolher arquivos'

### - importar dados

```
df = pd.read_csv('nome_do_dataframe')
```

### - visualizar primeiras linhas do dataframe

```
print(df.head())
```
---

## conhecendo os dados

### - visualizando estrutura do banco

```
print(f"seu dataset tem: {df.shape[0]} linhas e {df.shape[1]} colunas")
```

### - nome das colunas de forma organizadas
```
print(df.columns.tolist())
```

### - verificar dados faltantes

```
dados_faltantes = df.isnull().sum()
print(dados_faltantes)
```

### - verificar valores zerados em colunas numericas

```
df[['quantidade', 'preco_unitario', 'total_venda']].eq(0).sum()
````

### - resumo estatistico simples
```
print(df.describe())
```

---

## opera√ß√µes b√°sicas com python

### - somar coluna
```
print(df['total_venda'].sum())
```

### - multiplicar colunas
```
df['total_venda'] = df['quantidade'] * df['preco_unitario']
print(df['total_venda'])
```

### - media da coluna quantidade
```
print(df['quantidade'].mean())
```

---

## filtros

### - filtrar itens da categoria Eletr√¥nicos
```
print(df[df['categoria'] == 'Eletr√¥nicos'])
```

### - filtro composto ou combinado
```
print(df[(df['categoria'] == 'Eletr√¥nicos') & (df['quantidade'] > 3)])
```

---

## agrupamentos - group by

### - media de quantidade vendida por categoria
```
print(df.groupby('categoria')['quantidade'].mean())
```

### - m√∫ltiplas estatisticas por categoria
```
print(df.groupby('categoria')['quantidade'].agg(['mean', 'sum', 'count', 'max', 'min']))
```

---

## gr√°ficos

### - grafico simpes de barras
```
df['categoria'].value_counts().plot(kind= 'bar')
plt.show()
```

### - histograma de distribui√ß√£o dos valores de venda 'total_venda'
```
df['total_venda'].plot(kind= 'hist', bins = 20)
plt.show()
```

### - versao 2 do histograma
```
plt.figure(figsize =(8,6))
df['total_venda'].hist(bins=20)
plt.title('Distribui√ß√£o das vendas')
plt.xlabel('Valor das vendass')
plt.ylabel('Frequ√™ncia')
plt.show()
```

### - gr√°fico de barras horizontais com o 'total_venda'
```
df['categoria'].value_counts().plot(kind= 'barh')
plt.show()
```

### - gr√°fico de pizza com o 'total_venda'
```
df['categoria'].value_counts().plot(kind= 'pie')
plt.show()
```

---

## criando nova coluna: cliente vip ou comum

### - criar uma nova coluna status do cliente
```
df['status_cliente'] = np.where(df['total_venda'] > 10000, 'cliente vip', 'cliente comum')
```

---

## trabalhando com datas

### - garantir que as informa√ß√µes de data est√£o em formato datetime
```
df['data_venda'] = pd.to_datetime(df['data_venda'])
```

### - extraindo informa√ß√µes de datatime
```
df['ano_venda'] = df['data_venda'].dt.year
df['mes_venda'] = df['data_venda'].dt.month
df['dia_venda'] = df['data_venda'].dt.day
df['dia_da_semana'] = df['data_venda'].dt.dayofweek
```

---

**[Veja o script completo aqui, contendo an√°lise de oportunidades e an√°lise final](./firstanalysis_py.ipynb)**

---

## Roadmap de Aprendizado ‚Äî Pr√≥ximos M√≥dulos  

A seguir est√£o os m√≥dulos que ainda ser√£o estudados no curso **Dados do Zero**, al√©m das pr√≥ximas etapas do meu desenvolvimento como analista de dados:


### üîÑ Pr√≥ximos passos:

- Visualiza√ß√£o de Dados no **Looker Studio**
- Computa√ß√£o em Nuvem com **AWS**
- Controle de vers√£o com **Git e GitHub**
- Cria√ß√£o do meu primeiro **Portf√≥lio de Projetos em Dados**
- Desenvolvimento do **Plano de A√ß√£o para conquistar a primeira vaga** na √°rea de dados  
  (LinkedIn, curr√≠culo, posicionamento, networking)

---

üîé *O reposit√≥rio ser√° atualizado conforme cada m√≥dulo for conclu√≠do.*
